---
title: "Publications"
permalink: /publications/
author_profile: true
---

* <a href="https://arxiv.org/abs/2310.03646" style="text-decoration:none">**TRAM: Bridging Trust Regions and Sharpness Aware Minimization.**</a>
<a href="https://tomsherborne.github.io/" style="text-decoration:none">Tom Sherborne</a>, 
<a href="https://nsaphra.net/" style="text-decoration:none">Naomi Saphra</a>, 
<a href="https://pdasigi.github.io/" style="text-decoration:none">Pradeep Dasigi</a>, 
and
Hao Peng.
Preprint, 2023.\
<a href="https://github.com/tomsherborne/tram_optimizer" style="text-decoration:none">**[code]**</a>

* <a href="https://arxiv.org/abs/2309.10691" style="text-decoration:none">**MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback.**</a>
<a href="https://xingyaoww.github.io/" style="text-decoration:none">Xingyao Wang</a>, 
<a href="https://zihanwangki.github.io/" style="text-decoration:none">Zihan Wang</a>, 
<a href="https://lumos-jiateng.github.io/" style="text-decoration:none">Jiateng Liu</a>, 
<a href="https://yangyi-chen.github.io/" style="text-decoration:none">Yangyi Chen</a>, 
<a href="https://lifan-yuan.github.io/" style="text-decoration:none">Lifan Yuan</a>, 
Hao Peng, 
and 
<a href="http://blender.cs.illinois.edu/hengji.html" style="text-decoration:none">Heng Ji</a>.
Preprint, 2023.\
<a href="https://xingyaoww.github.io/mint-bench/" style="text-decoration:none">**[website]**</a>
<a href="https://github.com/xingyaoww/mint-bench" style="text-decoration:none">**[code]**</a>
<a href="https://github.com/xingyaoww/mint-bench/blob/main/docs/DATA.md" style="text-decoration:none">**[data]**</a>

* <a href="https://arxiv.org/abs/2309.17428" style="text-decoration:none">**CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets.**</a>
<a href="https://lifan-yuan.github.io/" style="text-decoration:none">Lifan Yuan</a>, 
<a href="https://yangyi-chen.github.io/" style="text-decoration:none">Yangyi Chen</a>, 
<a href="https://xingyaoww.github.io/" style="text-decoration:none">Xingyao Wang</a>, 
<a href="https://scholar.google.com/citations?user=eUae2K0AAAAJ&hl=en" style="text-decoration:none">Yi R. Fung</a>,
Hao Peng, 
and 
<a href="http://blender.cs.illinois.edu/hengji.html" style="text-decoration:none">Heng Ji</a>.  
Preprint, 2023.\
<a href="https://github.com/lifan-yuan/CRAFT" style="text-decoration:none">**[code]**</a>

* <a href="https://arxiv.org/abs/2310.09930" style="text-decoration:none">**FiLM: Fill-in Language Models for Any-Order Generation.**</a>
<a href="https://shentianxiao.github.io/" style="text-decoration:none">Tianxiao Shen</a>, 
Hao Peng, 
<a href="https://homes.cs.washington.edu/~shenr3/" style="text-decoration:none">Ruoqi Shen</a>,
<a href="https://franxyao.github.io/" style="text-decoration:none">Yao Fu</a>, 
<a href="https://faculty.washington.edu/zaid/" style="text-decoration:none">Zaid Harchaoui</a>,
and 
<a href="https://homes.cs.washington.edu/~yejin/" style="text-decoration:none">Yejin Choi</a>.
Preprint, 2023.\
<a href="https://github.com/shentianxiao/FiLM" style="text-decoration:none">**[code]**</a>

* <a href="https://arxiv.org/abs/2305.10142" style="text-decoration:none">**Improving Language Model
Negotiation with Self-Play and In-Context Learning from AI Feedback.**</a>
<a href="https://franxyao.github.io/" style="text-decoration:none">Yao Fu</a>, 
Hao Peng, 
<a href="https://allenai.org/team/tushark" style="text-decoration:none">Tushar Khot</a>, 
and 
<a href="https://homepages.inf.ed.ac.uk/mlap/" style="text-decoration:none">Mirella Lapata</a>.  
Preprint, 2023.\
<a href="https://github.com/FranxYao/GPT-Bargaining" style="text-decoration:none">**[code]**</a>

* <a href="https://arxiv.org/abs/2305.10314" style="text-decoration:none">**LeTI: Learning to Generate from Textual Interactions.**</a>
<a href="https://xingyaoww.github.io/" style="text-decoration:none">Xingyao Wang</a>, 
Hao Peng, 
<a href="https://reyhaneh.cs.illinois.edu/" style="text-decoration:none">Reyhaneh Jabbarvand</a>, 
and 
<a href="http://blender.cs.illinois.edu/hengji.html" style="text-decoration:none">Heng Ji</a>.  
Preprint, 2023.\
<a href="https://github.com/xingyaoww/LeTI" style="text-decoration:none">**[code]**</a>

* <a href="https://arxiv.org/abs/2307.09701" style="text-decoration:none">**Efficiency Pentathlon: A
Standardized Arena for Efficiency Evaluation.**</a>
Hao Peng, 
<a href="https://awk.ai/" style="text-decoration:none">Qingqing Cao</a>, 
<a href="https://jessedodge.github.io/" style="text-decoration:none">Jesse Dodge</a>, 
Matthew E. Peters, 
<a href="https://www.jaredfern.com/" style="text-decoration:none">Jared Fernandez</a>, 
<a href="https://tomsherborne.github.io/" style="text-decoration:none">Tom Sherborne</a>, 
<a href="https://kyleclo.github.io/" style="text-decoration:none">Kyle Lo</a>, 
Sam Skjonsberg, 
<a href="https://strubell.github.io/" style="text-decoration:none">Emma Strubell</a>, 
Darrell Plessas, 
<a href="https://beltagy.net/" style="text-decoration:none">Iz Beltagy</a>, 
Evan Pete Walsh, 
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>, 
and 
<a href="https://homes.cs.washington.edu/~hannaneh/" style="text-decoration:none">Hannaneh Hajishirzi</a>. 
Preprint, 2023.\
<a href="https://github.com/allenai/efficiency-pentathlon" style="text-decoration:none">**[code]**</a>


* <a href="https://arxiv.org/abs/2305.17306" style="text-decoration:none">**Chain-of-
Thought Hub: A Continuous Effort to Measure Large Language Modelsâ€™ Reasoning
Performance.**</a>
<a href="https://franxyao.github.io/" style="text-decoration:none">Yao Fu</a>, 
Litu Ou,
Mingyu Chen, 
Yuhao Wan, 
Hao Peng, 
and 
<a href="https://allenai.org/team/tushark" style="text-decoration:none">Tushar Khot</a>.\
Challenges of Deploying Generative AI Workshop at ICML, 2023.
<a href="https://github.com/FranxYao/chain-of-thought-hub" style="text-decoration:none">**[website]**</a>


* <a href="https://arxiv.org/abs/2301.12726" style="text-decoration:none">**Specializing
Smaller Language Models towards Multi-Step Reasoning.**</a>
<a href="https://franxyao.github.io/" style="text-decoration:none">Yao Fu</a>, 
Hao Peng, 
Litu Ou,
<a href="https://allenai.org/team/ashishs" style="text-decoration:none">Ashish Sabharwal</a>, 
and
<a href="https://allenai.org/team/tushark" style="text-decoration:none">Tushar Khot</a>.
In <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2023.
**Oral**.\
<a href="https://github.com/FranxYao/FlanT5-CoT-Specialization" style="text-decoration:none">**[code]**</a>
<a href="https://drive.google.com/drive/folders/1BOXcUTnEyvQia_ypHcaUnUbLsN4HzqmQ?usp=sharing" style="text-decoration:none">**[data]**</a>

* <a href="https://arxiv.org/abs/2210.00720" style="text-decoration:none">**Complexity-Based Prompting for Multi-Step Reasoning.**</a>
<a href="https://franxyao.github.io/" style="text-decoration:none">Yao Fu</a>, 
Hao Peng, 
<a href="https://allenai.org/team/ashishs" style="text-decoration:none">Ashish Sabharwal</a>, 
<a href="https://allenai.org/team/peterc" style="text-decoration:none">Peter Clark</a>, 
and
<a href="https://allenai.org/team/tushark" style="text-decoration:none">Tushar Khot</a>.
In <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2023.\
<a href="https://github.com/FranxYao/Complexity-Based-Prompting" style="text-decoration:none">**[code]**</a>

* <a href="https://arxiv.org/abs/2210.07468" style="text-decoration:none">**Transparency Helps Reveal When Language Models Learn Meaning.**</a>
<a href="https://zhaofengwu.github.io/" style="text-decoration:none">Zhaofeng Wu</a>,
<a href="https://lambdaviking.com/" style="text-decoration:none">William Merrill</a>,
Hao Peng,
<a href="https://beltagy.net/" style="text-decoration:none">Iz Beltagy</a>,
and
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
<em>Transactions of the Association for Computational Linguistics (TACL)</em>, 2022.

* <a href="https://arxiv.org/abs/2211.03495" style="text-decoration:none">**How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers.**</a>
Michael Hassid,
Hao Peng,
Daniel Rotem,
<a href="https://homes.cs.washington.edu/~jkasai/" style="text-decoration:none">Jungo Kasai</a>,
Ivan Montero,
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>,
and
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>.
In <em>Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP Findings)</em>, 2022.

* <a href="https://arxiv.org/abs/2210.08431" style="text-decoration:none">**Modeling Context With Linear Attention for Scalable Document-Level Translation.**</a>
<a href="https://zhaofengwu.github.io/" style="text-decoration:none">Zhaofeng Wu</a>,
Hao Peng,
<a href="https://nik0spapp.github.io/" style="text-decoration:none">Nikolaos Pappas</a>,
and
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP Findings)</em>, 2022.

* <a href="https://arxiv.org/abs/2205.09273" style="text-decoration:none">**Twist Decoding: Diverse Generators Guide Each Other.**</a>
<a href="https://homes.cs.washington.edu/~jkasai/" style="text-decoration:none">Jungo Kasai</a>,
<a href="https://keisuke-sakaguchi.github.io/" style="text-decoration:none">Keisuke Sakaguchi</a>,
<a href="https://rlebras.github.io/" style="text-decoration:none">Ronan Le Bras</a>,
Hao Peng,
Ximing Lu,
<a href="http://www.cs.yale.edu/homes/radev/" style="text-decoration:none">Dragomir Radev</a>,
<a href="https://homes.cs.washington.edu/~yejin/" style="text-decoration:none">Yejin Choi</a>,
and
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2022.

* <a href="https://arxiv.org/abs/2110.02488" style="text-decoration:none">**ABC: Attention with Bounded-memory Control.**</a>
Hao Peng, 
<a href="https://homes.cs.washington.edu/~jkasai/" style="text-decoration:none">Jungo Kasai</a>, 
<a href="https://nik0spapp.github.io" style="text-decoration:none">Nikolaos Pappas</a>, 
<a href="https://dyogatama.github.io" style="text-decoration:none">Dani Yogatama</a>,
<a href="https://zhaofengwu.github.io" style="text-decoration:none">Zhaofeng Wu</a>,
<a href="https://ikekonglp.github.io" style="text-decoration:none">Lingpeng Kong</a>,
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>,
and
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2022.
    
* <a href="https://arxiv.org/abs/2107.07150" style="text-decoration:none">**Tailor: Generating and Perturbing Text with Semantic Controls.**</a>
<a href="https://homes.cs.washington.edu/~wtshuang/" style="text-decoration:none">Tongshuang Wu</a>,
<a href="https://alexisjihyeross.github.io" style="text-decoration:none">Alexis Ross</a>, 
Hao Peng, 
Matthew E. Peters, 
and
<a href="https://matt-gardner.github.io" style="text-decoration:none">Matt Gardner</a>.
In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2022.

* <a href="https://arxiv.org/abs/2103.13076" style="text-decoration:none">**Finetuning Pretrained Transformers into RNNs.**</a>
<a href="https://homes.cs.washington.edu/~jkasai/" style="text-decoration:none">Jungo Kasai</a>, 
Hao Peng, 
<a href="https://dreasysnail.github.io" style="text-decoration:none">Yizhe Zhang</a>, 
<a href="https://dyogatama.github.io" style="text-decoration:none">Dani Yogatama</a>,
<a href="http://gabrielilharco.com" style="text-decoration:none">Gabriel Ilharco</a>, 
<a href="https://nik0spapp.github.io" style="text-decoration:none">Nikolaos Pappas</a>, 
<a href="https://www.microsoft.com/en-us/research/people/maoyi/" style="text-decoration:none">Yi Mao</a>, 
<a href="https://www.microsoft.com/en-us/research/people/wzchen/" style="text-decoration:none">Weizhu Chen</a>, 
and
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2021.

* <a href="https://arxiv.org/abs/2103.02143" style="text-decoration:none">**Random Feature Attention.**</a>
Hao Peng,
<a href="https://nik0spapp.github.io" style="text-decoration:none">Nikolaos Pappas</a>,
<a href="https://dyogatama.github.io" style="text-decoration:none">Dani Yogatama</a>,
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>,
<a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>,
and 
<a href="https://ikekonglp.github.io" style="text-decoration:none">Lingpeng Kong</a>.
In <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.
**Spotlight**.

* <a href="https://arxiv.org/abs/2006.10369" style="text-decoration:none">**Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation.**</a>
<a href="https://homes.cs.washington.edu/~jkasai/" style="text-decoration:none">Jungo Kasai</a>,
<a href="https://nik0spapp.github.io" style="text-decoration:none">Nikolaos Pappas</a>,
Hao Peng, 
James Cross,
and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.

* <a href="https://arxiv.org/abs/2009.07502" style="text-decoration:none">**Contextualized Perturbation for Textual Adversarial Attack.**</a>
Dianqi Li,
<a href="https://dreasysnail.github.io" style="text-decoration:none">Yizhe Zhang</a>,
Hao Peng,
Liqun Chen,
<a href="https://www.microsoft.com/en-us/research/people/chrisbkt/" style="text-decoration:none">Chris Brockett</a>,
<a href="https://people.ece.uw.edu/sun/" style="text-decoration:none">Ming-Ting Sun</a>,
and <a href="https://www.microsoft.com/en-us/research/people/billdol/" style="text-decoration:none">Bill Dolan</a>.
In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2021.

* <a href="https://arxiv.org/abs/2012.05395" style="text-decoration:none">**Infusing Finetuning with Semantic Dependencies.**</a>
<a href="https://zhaofengwu.github.io" style="text-decoration:none">Zhaofeng Wu</a>,
Hao Peng, 
and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
<em>Transactions of the Association for Computational Linguistics (TACL)</em>, 2020.

* <a href="https://aclanthology.org/2020.acl-main.587.pdf" style="text-decoration:none">**A Mixture of h âˆ’ 1 Heads is Better than h Heads.**</a> 
Hao Peng,
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>,
Dianqi Li, 
and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2020.

* <a href="https://arxiv.org/abs/1909.02134" style="text-decoration:none">**PaLM: A Hybrid Parser and Language Model.**</a>
Hao Peng,
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>,
and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2019.

* <a href="https://aclanthology.org/D19-1110/" style="text-decoration:none">**RNN Architecture Learning with Sparse Regularization.**</a>
<a href="http://www.cs.cmu.edu/~jessed/" style="text-decoration:none">Jesse Dodge</a>,
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>,
Hao Peng,
and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2019.

* <a href="https://arxiv.org/abs/1904.04428" style="text-decoration:none">**Text Generation with Exemplar-based Adaptive Decoding.**</a>
Hao Peng, <a href="https://www.cs.cmu.edu/~apparikh/" style="text-decoration:none">Ankur P. Parikh</a>, <a href="https://www.manaalfaruqui.com" style="text-decoration:none">Manaal Faruqui</a>, 
<a href="http://www.cs.cmu.edu/~bdhingra/" style="text-decoration:none">Bhuwan Dhingra</a>,
and <a href="http://www.dipanjandas.com" style="text-decoration:none">Dipanjan Das</a>.
In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2019.

* <a href="https://arxiv.org/abs/1808.09357" style="text-decoration:none">**Rational Recurrences.**</a>
Hao Peng,
<a href="https://schwartz-lab-huji.github.io" style="text-decoration:none">Roy Schwartz</a>,
<a href="http://samthomson.com" style="text-decoration:none">Sam Thomson</a>, and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2018.

* <a href="https://arxiv.org/abs/1805.04658" style="text-decoration:none">**Backpropagating through Structured Argmax using a SPIGOT.**</a>
Hao Peng, <a href="http://samthomson.com" style="text-decoration:none">Sam Thomson</a>,  and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2018.
**Best Paper Honorable Mention**<br>

* <a href="https://arxiv.org/abs/1804.05990" style="text-decoration:none">**Learning Joint Semantic Parsers from Disjoint Data.**</a>
Hao Peng, <a href="http://samthomson.com" style="text-decoration:none">Sam Thomson</a>, <a href="https://swabhs.com/" style="text-decoration:none">Swabha Swayamdipta</a>, and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2018.

* <a href="https://arxiv.org/abs/1802.08690" style="text-decoration:none">**"You are no Jack Kennedy": On Media Selection of Highlights from Presidential Debate.**</a>
<a href="https://chenhaot.com" style="text-decoration:none">Chenhao Tan</a>, Hao Peng, and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of The Web Conference (WWW)</em>, 2018.

* <a href="https://arxiv.org/abs/1704.06855" style="text-decoration:none">**Deep Multitask Learning for Semantic Dependency Parsing.**</a>
Hao Peng, <a href="http://samthomson.com" style="text-decoration:none">Sam Thomson</a>, and <a href="http://homes.cs.washington.edu/~nasmith/" style="text-decoration:none">Noah A. Smith</a>.
In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2017.

* <a href="https://aclanthology.org/P16-1037/" style="text-decoration:none">**News Citation Recommendation with Implicit and Explicit Semantics.**</a>
Hao Peng, <a href="https://www.machinereading.ai/" style="text-decoration:none">Jing Liu</a>, and <a href="https://www.microsoft.com/en-us/research/people/cyl/" style="text-decoration:none">Chin-Yew Lin</a>.
In <em>Proceedings of the Annual Meeting of the Association for Computational Linguisticss (ACL)</em>, 2016.

* <a href="https://arxiv.org/abs/1602.03001" style="text-decoration:none">**A Convolutional Attention Network for Extreme Summarization of Source Code.**</a>
<a href="https://miltos.allamanis.com" style="text-decoration:none">Miltiadis Allamanis</a>, Hao Peng, and <a href="http://homepages.inf.ed.ac.uk/csutton/" style="text-decoration:none">Charles Sutton</a>.
In <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2016.

* <a href="https://arxiv.org/abs/1504.01106" style="text-decoration:none">**Discriminative Neural Sentence Modeling by Tree-based Convolution.**</a>
<a href="https://lili-mou.github.io" style="text-decoration:none">Lili Mou</a>\*, Hao Peng\*, Ge Li, Yan Xu, Lu Zhang, and Zhi Jin (\*: Equal contribution).
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2015.

* <a href="https://arxiv.org/abs/1508.03720" style="text-decoration:none">**Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths.**</a>
Yan Xu, <a href="https://lili-mou.github.io" style="text-decoration:none">Lili Mou</a>, Ge Li, Yunchuan Chen, Hao Peng, and Zhi Jin.
In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2015.
